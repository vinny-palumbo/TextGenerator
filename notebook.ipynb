{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Text Generation with Recurrent Neural Networks\n",
    "\n",
    "In this project, I've implemented a Recurrent Neural Network with an LSTM architecture that generates sentences based on \"The Adventures of Sherlock Holmes\" by Arthur Conan Doyle, by building them up character-by-character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read and clean the text dataset \n",
    "Read in the text, transforming everything to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text has 581864 characters\n"
     ]
    }
   ],
   "source": [
    "text = open('datasets/The-Adventures-of-Sherlock-Holmes.txt').read().lower()\n",
    "print('the text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print out the first characters of the raw text to get a sense of what we need to throw out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffproject gutenberg's the adventures of sherlock holmes, by arthur conan doyle\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.net\\n\\n\\ntitle: the adventures of sherlock holmes\\n\\nauthor: arthur conan doyle\\n\\nposting date: april 18, 2011 [ebook #1661]\\nfirst posted: november 29, 2002\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook the adventures of sherlock holmes ***\\n\\n\\n\\n\\nproduced by an anonymous project gutenberg volunteer and jose menendez\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nthe adventures of sherlock holmes\\n\\nby\\n\\nsir arthur conan doyle\\n\\n\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a dist\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Cut out the first characters that are not part of the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = text[1198:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Remove line break characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = text.replace('\\n',' ') \n",
    "text = text.replace('\\r',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets see how the first characters of our text look now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" sherlock holmes she is always the woman. i have seldom heard him mention her under any other name. in his eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer--excellent for drawing the veil from men's motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene adler, of dubious and questionable memory.  i had seen little of holmes lately. my marriage had drifted us away from each other. my own complete happiness, and the home-centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while holmes, who loathed every form of society with his whole bohemian soul, remained in our lodgings in baker street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. he was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. from time to time i heard some vag\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print all different unique characters that appear in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '!',\n",
       " '\"',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " '@',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'à',\n",
       " 'â',\n",
       " 'è',\n",
       " 'é'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Replace any unwanted characters with the space character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import regular expressions library\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cleaned_text(text):\n",
    "    punctuation = ['!', ',', '.', ':', ';', '?']\n",
    "    text_clean = ''\n",
    "    for char in set(text):\n",
    "        if (re.match('[a-z ]',char) is None) and (char not in punctuation):\n",
    "            text = text.replace(char,' ')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = cleaned_text(text)\n",
    "\n",
    "# shorten any extra dead space created above\n",
    "text = text.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '!',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print out some statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 573785 total number of characters\n",
      "this corpus has 33 unique characters\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print (\"this corpus has \" +  str(len(text)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cut data into input/output pairs\n",
    "\n",
    "Slide a window of length $T$ along the text corpus. Everything in the window becomes one input while the character following becomes its corresponding output.  This process of extracting input/output pairs is illustrated in the gif below on a small example text using a window size of T = 5.\n",
    "\n",
    "<img src=\"images/text_windowing_training.gif\" width=400 height=400/>\n",
    "\n",
    "We do not need to slide the window along one character at a time but can move by a fixed step size $M$ greater than 1 (in the gif indeed $M = 1$).  This is done with large input texts (like ours which has over 500,000 characters!) when sliding the window along one character at a time we would create far too many input/output pairs to be able to reasonably compute with.\n",
    "\n",
    "Sliding a window of size T = 5 with a step length of M = 1 (these are the parameters shown in the gif above) over this sequence produces the following list of input/output pairs\n",
    "\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Each input is a sequence (or vector) of 5 characters (and in general has length equal to the window size T) while each corresponding output is a single character.  We created around P total number of input/output pairs  (for general step size M we create around ceil(P/M) pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This function runs a sliding window along the input text and creates associated input/output pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def window_transform_text(text, window_size, step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    for n in range(0, len(text)-window_size, step_size):\n",
    "        inputs.append(text[n:n+window_size])\n",
    "        outputs.append(text[n+window_size])\n",
    "\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract input/output pairs with the sliding window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "step_size = 5\n",
    "inputs, outputs = window_transform_text(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print out a few input/output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input =  the woman. i have seldom heard him mention her under any other name. in his eyes she eclipses and p\n",
      "output = r\n",
      "--------------\n",
      "input = oke of the softer passions, save with a gibe and a sneer. they were admirable things for the observe\n",
      "output = r\n"
     ]
    }
   ],
   "source": [
    "# print out a few of the input/output pairs to verify that we've made the right kind of stuff to learn from\n",
    "print('input = ' + inputs[6])\n",
    "print('output = ' + outputs[6])\n",
    "print('--------------')\n",
    "print('input = ' + inputs[101])\n",
    "print('output = ' + outputs[101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encoding the characters\n",
    "\n",
    "Transform each character in our inputs/outputs into a vector with length equal to the number of unique characters in our text. This vector is all zeros except one location where we place a 1 - and this location is unique to each character type.  e.g., we transform 'a', 'b', and 'c' as follows\n",
    "\n",
    "$$a\\longleftarrow\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,\\,\\,b\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,c\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0 \n",
    "\\end{array}\\right]\\cdots$$\n",
    "\n",
    "where number of entries = number of unique characters in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Form a dictionary mapping each unique character to a unique integer, and one dictionary to do the reverse mapping.  We can then use these dictionaries to quickly make our one-hot encodings, as well as re-translate (from integers to characters) the results of our trained RNN classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this dictionary maps each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# this dictionary maps each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This function takes in the raw character input/outputs and returns their numerical versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_io_pairs(text,window_size,step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty matrix for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and transform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One-hot encode the input/output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "step_size = 5\n",
    "X,y = encode_io_pairs(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build and train the Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(window_size,len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = X[:100000]\n",
    "y_train = y[:100000]\n",
    "\n",
    "X_test = X[-1000:]\n",
    "y_test = y[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100000/100000 [==============================] - 38s - loss: 2.7609    \n",
      "Epoch 2/100\n",
      "100000/100000 [==============================] - 33s - loss: 2.3762    \n",
      "Epoch 3/100\n",
      "100000/100000 [==============================] - 33s - loss: 2.2126    \n",
      "Epoch 4/100\n",
      "100000/100000 [==============================] - 32s - loss: 2.1169    \n",
      "Epoch 5/100\n",
      "100000/100000 [==============================] - 32s - loss: 2.0436    \n",
      "Epoch 6/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.9826    \n",
      "Epoch 7/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.9340    \n",
      "Epoch 8/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.8897    \n",
      "Epoch 9/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.8525    \n",
      "Epoch 10/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.8184    \n",
      "Epoch 11/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.7879    \n",
      "Epoch 12/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.7601    \n",
      "Epoch 13/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.7344    \n",
      "Epoch 14/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.7104    \n",
      "Epoch 15/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.6880    \n",
      "Epoch 16/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.6666    \n",
      "Epoch 17/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.6468    \n",
      "Epoch 18/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.6269    \n",
      "Epoch 19/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.6088    \n",
      "Epoch 20/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.5915    \n",
      "Epoch 21/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.5742    \n",
      "Epoch 22/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.5583    \n",
      "Epoch 23/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.5421    \n",
      "Epoch 24/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.5264    \n",
      "Epoch 25/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.5118    \n",
      "Epoch 26/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4966    \n",
      "Epoch 27/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4831    \n",
      "Epoch 28/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4695    \n",
      "Epoch 29/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4556    \n",
      "Epoch 30/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4423    \n",
      "Epoch 31/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4297    \n",
      "Epoch 32/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4169    \n",
      "Epoch 33/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.4040    \n",
      "Epoch 34/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3917    \n",
      "Epoch 35/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3795    \n",
      "Epoch 36/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3676    \n",
      "Epoch 37/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3558    \n",
      "Epoch 38/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3450    \n",
      "Epoch 39/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3331    \n",
      "Epoch 40/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3214    \n",
      "Epoch 41/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.3101    \n",
      "Epoch 42/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2990    \n",
      "Epoch 43/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2878    \n",
      "Epoch 44/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2772    \n",
      "Epoch 45/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2662    \n",
      "Epoch 46/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2562    \n",
      "Epoch 47/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2452    \n",
      "Epoch 48/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2349    \n",
      "Epoch 49/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2234    \n",
      "Epoch 50/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2140    \n",
      "Epoch 51/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.2037    \n",
      "Epoch 52/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1938    \n",
      "Epoch 53/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1842    \n",
      "Epoch 54/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1739    \n",
      "Epoch 55/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1634    \n",
      "Epoch 56/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1533    \n",
      "Epoch 57/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1444    \n",
      "Epoch 58/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1341    \n",
      "Epoch 59/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1249    \n",
      "Epoch 60/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1154    \n",
      "Epoch 61/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.1060    \n",
      "Epoch 62/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0966    \n",
      "Epoch 63/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0886    \n",
      "Epoch 64/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0794    \n",
      "Epoch 65/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0707    \n",
      "Epoch 66/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0619    \n",
      "Epoch 67/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0547    \n",
      "Epoch 68/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0468    \n",
      "Epoch 69/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0394    \n",
      "Epoch 70/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0321    \n",
      "Epoch 71/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0248    \n",
      "Epoch 72/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0165    \n",
      "Epoch 73/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0093    \n",
      "Epoch 74/100\n",
      "100000/100000 [==============================] - 32s - loss: 1.0018    \n",
      "Epoch 75/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9962    \n",
      "Epoch 76/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9899    \n",
      "Epoch 77/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9837    \n",
      "Epoch 78/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9774    \n",
      "Epoch 79/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9716    \n",
      "Epoch 80/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9668    \n",
      "Epoch 81/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9608    \n",
      "Epoch 82/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9534    \n",
      "Epoch 83/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9487    \n",
      "Epoch 84/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9450    \n",
      "Epoch 85/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9394    \n",
      "Epoch 86/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9352    \n",
      "Epoch 87/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9311    \n",
      "Epoch 88/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9278    \n",
      "Epoch 89/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9222    \n",
      "Epoch 90/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9167    \n",
      "Epoch 91/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9141    \n",
      "Epoch 92/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9111    \n",
      "Epoch 93/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9070    \n",
      "Epoch 94/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.9036    \n",
      "Epoch 95/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.8992    \n",
      "Epoch 96/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.8953    \n",
      "Epoch 97/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.8919    \n",
      "Epoch 98/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.8890    \n",
      "Epoch 99/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.8856    \n",
      "Epoch 100/100\n",
      "100000/100000 [==============================] - 32s - loss: 0.8827    \n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, epochs=100, verbose=1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the model weights, if not already loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_weights/best_RNN_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print out training and testing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.846618039694\n",
      "testing error = 3.19366179657\n"
     ]
    }
   ],
   "source": [
    "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('training error = ' + str(training_error))\n",
    "\n",
    "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('testing error = ' + str(testing_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This function uses the trained model to predict a desired number of future characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_next_chars(model,input_chars,num_to_predict):     \n",
    "    # create output\n",
    "    predicted_chars = ''\n",
    "    for i in range(num_to_predict):\n",
    "        # convert this round's predicted characters to numerical input    \n",
    "        x_test = np.zeros((1, window_size, len(chars)))\n",
    "        for t, char in enumerate(input_chars):\n",
    "            x_test[0, t, chars_to_indices[char]] = 1.\n",
    "\n",
    "        # make this round's prediction\n",
    "        test_predict = model.predict(x_test,verbose = 0)[0]\n",
    "\n",
    "        # translate numerical prediction back to characters\n",
    "        r = np.argmax(test_predict) # predict class of each test input\n",
    "        d = indices_to_chars[r] \n",
    "\n",
    "        # update predicted_chars and input\n",
    "        predicted_chars+=d\n",
    "        input_chars+=d\n",
    "        input_chars = input_chars[1:]\n",
    "    return predicted_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Generate text using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      " sherlock holmes she is always the woman. i have seldom heard him mention her under any other name. \"\n",
      "\n",
      "predicted chars = \n",
      "his faceston, i say she return to see the man who was a presulaliest, and they were that there is the best patt the strang of his fact took about the recorricair an the attempse. the morent the street.  whate you can in the tire of the has beent his \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      ".  come in! said holmes. a man entered who could hardly have been less than six feet six inches in h\"\n",
      "\n",
      "predicted chars = \n",
      "errow hastrad to preced the starter was the newation. wh shere shattement her beward from his leavy stop his lits at the down into the certain which in the standing one of the man side of a man and the matter pressical shigh the class op as toen to b\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "hat will you do?  we shall spend the night in your room, and we shall investigate the cause of this \"\n",
      "\n",
      "predicted chars = \n",
      "mar. he shall when house that there was a cread of a wammant the done was blen shigh the time before the chas is was do the grest to the strange one which have been sucked to have seened the room.  nereches, it it is a stappion the best interest the \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_inds = [0, 10200, 350000]\n",
    "\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 250)\n",
    "\n",
    "    # print out input characters\n",
    "    line = '-------------------' + '\\n'\n",
    "    print(line)\n",
    "\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    predict_line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(predict_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see, character-by-character text generation isn't ideal for generating valid english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
